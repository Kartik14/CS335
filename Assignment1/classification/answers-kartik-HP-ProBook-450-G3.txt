Task 2:

1) It can be seen from "plot_iterations.png" of examples seen vs train/test accuracy that initially as the number of examples seen increases, both the training and test accuracy increases at a very fast rate. After around ~ 2500 data points, both the training and the test accuracy achieves the plateau and fluctuates in a small range for the rest of the data points. Thus this shows that the at ~2500 data points, the preceptron has linearly seperated the data points as best as it could and is not able to achieve a better seperation later on. Also the training accuracy is better than the test accuracy which is expected since we are fitting our perceptron for the training data.

2) From the plot "plot_training.png" it can seen that the test accuracy increases with the size of training set whereas the training accuracy discreases with them getting closer and closer with increasing as the training set size increases. The reason for this is that with less training data, it is easier for the percetron to classify it thus achieving a good training accuracy but this percetron does not generalise well to the test data. As the size of the training data increases, although the training accuracy deacreases because of the difficulty of perceptron to linearly classify more data. the perceptron also generalises better to "unseen" test data. This can be explained statistically using the VC inequality.

Answer to question:

Since the classifier has seen no data so far, all the k (= number of data labels) weight vector are all zero. Thus sigma(f_i*w_i) will be zero for all the data labels. So the prediction will be based on how we are breaking ties in our model. The expected accuracy of such a classifier will be (1/k) since the data point can take any of the k data labels with equal probability.

Task 3.1)

With t = 800 and s = 8000, for 1vr perceptron, the training accuracy achieved is 71.3% whereas for the 1v1 perceptron the training accuracy is 71.5%. For the whole dataset (t = 80000 and s = 20000), the 1vr perceptron gives a 73.8% accuracy and the 1v1 perceptron gives 78.8% accuracy. It can be seen that the 1v1 perceptron achieves a better final accuracy than the 1vr perceptron but also takes more iteration to converge. This can be attributed to the fact the 1v1 perceptron maintains S = k(k-1)/2 weights (where k is the number of discrete data labels) in contrast to the !vr perceptron and is thus a more complex Hypothesis set. Thus this allows a better classification of the data but also takes more time to find the best hypothesis function (i.e. the weights of the classifier) among the hypothesis set.
